{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthasu12/TA-Strike-Analysis-For-Daily-Nexus/blob/main/TAStrikeReddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRE63j0ep6S6"
      },
      "outputs": [],
      "source": [
        "#install praw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3TaMtx04_CL"
      },
      "outputs": [],
      "source": [
        "pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gL5YLr0-5CtL"
      },
      "outputs": [],
      "source": [
        "#imports for reddit scraping/diagrams\n",
        "import praw\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import nltk                               \n",
        "from nltk.corpus import twitter_samples    \n",
        "import matplotlib.pyplot as plt            \n",
        "import random                             \n",
        "import re                                 \n",
        "import string                             \n",
        "from nltk.corpus import stopwords          \n",
        "from nltk.stem import PorterStemmer       \n",
        "from nltk.tokenize import word_tokenize   \n",
        "from textblob import TextBlob\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdxt4N9MLJGQ"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wIEV7kGA8GIc"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.dpi'] = 200\n",
        "plt.rcParams['savefig.dpi'] = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eaNHP2NNYQjl"
      },
      "outputs": [],
      "source": [
        "#my developer access code\n",
        "reddit_read_only = praw.Reddit(client_id=\"RGdKiAFJPXF58ib0Tr4fcw\",\n",
        "                               client_secret=\"1hXSX11y-nMi8Fobsp9NDMiT7s0mMA\",\n",
        "                               user_agent=\"TA Strike Scraper UCSB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rjHAVMWhZlI8"
      },
      "outputs": [],
      "source": [
        "#the subreddit that I'm using\n",
        "subreddit = reddit_read_only.subreddit(\"UCSantaBarbara\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p5w9Lx28KEyw"
      },
      "outputs": [],
      "source": [
        "#checking for keywords\n",
        "keyword_list = [\"strike\", \"grads\", \"salary\", \"wages\", \"cola\", \" uaw \", \"union\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnmIYzXJKbkx"
      },
      "outputs": [],
      "source": [
        "title0 = []\n",
        "selftext0 = []\n",
        "comment0 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,11,7,0,0,0) < dt < datetime.datetime(2022,11,13,11,59,59):\n",
        "    title0.append(post.title)\n",
        "    selftext0.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment0.append(comment.body)\n",
        "\n",
        "title1 = []\n",
        "selftext1 = []\n",
        "comment1 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,11,14,0,0,0) < dt < datetime.datetime(2022,11,20,11,59,59):\n",
        "    title1.append(post.title)\n",
        "    selftext1.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment1.append(comment.body)\n",
        "\n",
        "title2 = []\n",
        "selftext2 = []\n",
        "comment2 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,11,21,0,0,0) < dt < datetime.datetime(2022,11,27,11,59,59):\n",
        "    title2.append(post.title)\n",
        "    selftext2.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment2.append(comment.body)\n",
        "\n",
        "title3 = []\n",
        "selftext3 = []\n",
        "comment3 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,11,28,0,0,0) < dt < datetime.datetime(2022,12,4,11,59,59):\n",
        "    title3.append(post.title)\n",
        "    selftext3.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment3.append(comment.body)\n",
        "\n",
        "title4 = []\n",
        "selftext4 = []\n",
        "comment4 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,12,5,0,0,0) < dt < datetime.datetime(2022,12,11,11,59,59):\n",
        "    title4.append(post.title)\n",
        "    selftext4.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment4.append(comment.body)\n",
        "\n",
        "title5 = []\n",
        "selftext5 = []\n",
        "comment5 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,12,12,0,0,0) < dt < datetime.datetime(2022,12,18,11,59,59):\n",
        "    title5.append(post.title)\n",
        "    selftext5.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment5.append(comment.body)\n",
        "\n",
        "title6 = []\n",
        "selftext6 = []\n",
        "comment6 = []\n",
        "for post in subreddit.new(limit=3000):\n",
        "  dt=datetime.datetime.utcfromtimestamp(post.created_utc)\n",
        "  if datetime.datetime(2022,12,19,0,0,0) < dt < datetime.datetime(2022,12,25,11,59,59):\n",
        "    title6.append(post.title)\n",
        "    selftext6.append(post.selftext)\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments.list():\n",
        "      comment6.append(comment.body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iQT000GsLTJZ"
      },
      "outputs": [],
      "source": [
        "#making a list of titles\n",
        "titles_list0=[]\n",
        "for title in title0:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list0.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list1=[]\n",
        "for title in title1:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list1.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list2=[]\n",
        "for title in title2:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list2.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list3=[]\n",
        "for title in title3:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list3.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list4=[]\n",
        "for title in title4:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list4.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list5=[]\n",
        "for title in title5:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list5.append(title)\n",
        "      added = True\n",
        "\n",
        "titles_list6=[]\n",
        "for title in title6:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in title.lower() and added == False:\n",
        "      titles_list6.append(title)\n",
        "      added = True\n",
        "\n",
        "#making a list of selftexts\n",
        "selftexts_list0 = []\n",
        "for selftext in selftext0:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list0.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list1 = []\n",
        "for selftext in selftext1:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list1.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list2 = []\n",
        "for selftext in selftext2:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list2.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list3 = []\n",
        "for selftext in selftext3:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list3.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list4 = []\n",
        "for selftext in selftext4:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list4.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list5 = []\n",
        "for selftext in selftext5:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list5.append(selftext)\n",
        "      added = True\n",
        "\n",
        "selftexts_list6 = []\n",
        "for selftext in selftext6:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in selftext.lower() and added == False:\n",
        "      selftexts_list6.append(selftext)\n",
        "      added = True\n",
        "\n",
        "#making a list of all comments and replies\n",
        "comments_list0 = []\n",
        "for comment in comment0:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list0.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list1 = []\n",
        "for comment in comment1:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list1.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list2 = []\n",
        "for comment in comment2:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list2.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list3 = []\n",
        "for comment in comment3:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list3.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list4 = []\n",
        "for comment in comment4:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list4.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list5 = []\n",
        "for comment in comment5:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list5.append(comment)\n",
        "      added = True\n",
        "\n",
        "comments_list6 = []\n",
        "for comment in comment6:\n",
        "  added = False\n",
        "  for keyword in keyword_list:\n",
        "    if keyword in comment.lower() and added == False:\n",
        "      comments_list6.append(comment)\n",
        "      added = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eItAq2LMX7-",
        "outputId": "dc74900f-ed7b-4aa9-c393-61dbba025268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Week 0 lengths of titles: 2, selftexts: 4, comments: 13\n",
            "Week 1 lengths of titles: 11, selftexts: 9, comments: 205\n",
            "Week 2 lengths of titles: 2, selftexts: 3, comments: 43\n",
            "Week 3 lengths of titles: 6, selftexts: 9, comments: 75\n",
            "Week 4 lengths of titles: 12, selftexts: 10, comments: 292\n",
            "Week 5 lengths of titles: 2, selftexts: 3, comments: 21\n",
            "Week 6 lengths of titles: 2, selftexts: 1, comments: 31\n"
          ]
        }
      ],
      "source": [
        "#check the length for the results\n",
        "print(f'Week 0 lengths of titles: {len(titles_list0)}, selftexts: {len(selftexts_list0)}, comments: {len(comments_list0)}')\n",
        "print(f'Week 1 lengths of titles: {len(titles_list1)}, selftexts: {len(selftexts_list1)}, comments: {len(comments_list1)}')\n",
        "print(f'Week 2 lengths of titles: {len(titles_list2)}, selftexts: {len(selftexts_list2)}, comments: {len(comments_list2)}')\n",
        "print(f'Week 3 lengths of titles: {len(titles_list3)}, selftexts: {len(selftexts_list3)}, comments: {len(comments_list3)}')\n",
        "print(f'Week 4 lengths of titles: {len(titles_list4)}, selftexts: {len(selftexts_list4)}, comments: {len(comments_list4)}')\n",
        "print(f'Week 5 lengths of titles: {len(titles_list5)}, selftexts: {len(selftexts_list5)}, comments: {len(comments_list5)}')\n",
        "print(f'Week 6 lengths of titles: {len(titles_list6)}, selftexts: {len(selftexts_list6)}, comments: {len(comments_list6)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making the dataframe based on the week you choose\n",
        "week0_newlist=titles_list0+selftexts_list0+comments_list0\n",
        "reddit_string0 = ' '\n",
        "df0 = pd.DataFrame(week0_newlist, columns=['Week 0'])\n",
        "comments=df0['Week 0']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 0'].replace('\\n', '')\n",
        "  reddit_string0 += comment\n",
        "\n",
        "week1_newlist=titles_list1+selftexts_list1+comments_list1\n",
        "reddit_string1 = ' '\n",
        "df1 = pd.DataFrame(week1_newlist, columns=['Week 1'])\n",
        "comments=df1['Week 1']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 1'].replace('\\n', '')\n",
        "  reddit_string1 += comment\n",
        "\n",
        "week2_newlist=titles_list2+selftexts_list2+comments_list2\n",
        "reddit_string2 = ' '\n",
        "df2 = pd.DataFrame(week2_newlist, columns=['Week 2'])\n",
        "comments=df2['Week 2']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 2'].replace('\\n', '')\n",
        "  reddit_string2 += comment\n",
        "\n",
        "week3_newlist=titles_list3+selftexts_list3+comments_list3\n",
        "reddit_string3 = ' '\n",
        "df3 = pd.DataFrame(week3_newlist, columns=['Week 3'])\n",
        "comments=df3['Week 3']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 3'].replace('\\n', '')\n",
        "  reddit_string3 += comment\n",
        "\n",
        "week4_newlist=titles_list4+selftexts_list4+comments_list4\n",
        "reddit_string4 = ' '\n",
        "df4 = pd.DataFrame(week4_newlist, columns=['Week 4'])\n",
        "comments=df4['Week 4']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 4'].replace('\\n', '')\n",
        "  reddit_string4 += comment\n",
        "\n",
        "week5_newlist=titles_list5+selftexts_list5+comments_list5\n",
        "reddit_string5 = ' '\n",
        "df5 = pd.DataFrame(week5_newlist, columns=['Week 5'])\n",
        "comments=df5['Week 5']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 5'].replace('\\n', '')\n",
        "  reddit_string5 += comment\n",
        "\n",
        "week6_newlist=titles_list6+selftexts_list6+comments_list6\n",
        "reddit_string6 = ' '\n",
        "df6 = pd.DataFrame(week2_newlist, columns=['Week 6'])\n",
        "comments=df6['Week 6']\n",
        "comments=comments.to_frame()\n",
        "for idx, row in comments.iterrows():\n",
        "  comment = row['Week 6'].replace('\\n', '')\n",
        "  reddit_string6 += comment"
      ],
      "metadata": {
        "id": "UKslt_pZmSlp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saveddataframe=pd.concat([df0,df1,df2,df3,df4,df5,df6], axis=1)\n",
        "print(saveddataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4lY15nIPrrY",
        "outputId": "7862b10a-d2be-4e18-e5f0-4a5916474448"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Week 0  \\\n",
            "0  Graduate students in the UAW are scheduled to ...   \n",
            "1  A.S. Senator files Judicial Council case again...   \n",
            "2  What has helped you learn the material??  I’m ...   \n",
            "3  anyone in comm 107 know if our ta is going on ...   \n",
            "4   \\n\\nAcademic  workers in the United Auto Work...   \n",
            "\n",
            "                                              Week 1  \\\n",
            "0  Biggest union strike in higher education US hi...   \n",
            "1  week 1 of the largest strike in higher ed in t...   \n",
            "2  Would the striking TAs get their November salary?   \n",
            "3                     How do I get a strike T-shirt?   \n",
            "4  Hey guys I think I found a real solution that ...   \n",
            "\n",
            "                                              Week 2  \\\n",
            "0                                             Strike   \n",
            "1  All Out to Win the UC-Wide Student Workers Str...   \n",
            "2  If I get one more email from ucsb, or see anot...   \n",
            "3  Currently scheduling my flight back to IV base...   \n",
            "4  Interesting how the COLA strike in 2020 only s...   \n",
            "\n",
            "                                              Week 3  \\\n",
            "0            strike + grades + losing financial aid…   \n",
            "1                                    strike? grades?   \n",
            "2  No COLA, No Contract! Build rank-and-file stri...   \n",
            "3  Dear striker with the “ABOLISH WORK” sign: Wha...   \n",
            "4                        Students against the strike   \n",
            "\n",
            "                                              Week 4  \\\n",
            "0  The TAs Union and the UC system have agreed to...   \n",
            "1  4 Quick things you can do to help your GSIs en...   \n",
            "2  The “strikes are supposed to be disruptive” ar...   \n",
            "3  What happened to the strike not effecting the ...   \n",
            "4  UC strikers in San Diego blocked a surfline ca...   \n",
            "\n",
            "                                              Week 5  \\\n",
            "0                               Instructor on strike   \n",
            "1       Made this at the beginning of the UC strike.   \n",
            "2  Does anyone have an instructor who is on strik...   \n",
            "3  does anyone know when the deadline is for f22 ...   \n",
            "4  I know its after the Dec 2 deadline for the TA...   \n",
            "\n",
            "                                              Week 6  \n",
            "0                                             Strike  \n",
            "1  All Out to Win the UC-Wide Student Workers Str...  \n",
            "2  If I get one more email from ucsb, or see anot...  \n",
            "3  Currently scheduling my flight back to IV base...  \n",
            "4  Interesting how the COLA strike in 2020 only s...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7n7ufNZZxKK",
        "outputId": "df8986c8-0a30-4f4a-a54b-f192ea29137f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.093, 'neu': 0.798, 'pos': 0.109, 'compound': 0.9937}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqDWVlF1hvj3",
        "outputId": "ec78e9ac-db7e-406c-e56b-b6a96d17750b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.081, 'neu': 0.801, 'pos': 0.118, 'compound': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JimVhoiAiBeq",
        "outputId": "287f0389-e64d-4bae-c5e9-3456a14e24c5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.106, 'neu': 0.795, 'pos': 0.099, 'compound': 0.9313}"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2lLOMiIiE8A",
        "outputId": "3fa192cf-b037-4854-e264-d26f7db34311"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.12, 'neu': 0.776, 'pos': 0.105, 'compound': -0.9987}"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVb0iPW4iHyN",
        "outputId": "8a63681c-a6e1-42af-f60d-2e0a14e4d884"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.132, 'neu': 0.757, 'pos': 0.111, 'compound': -0.9999}"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7DIoWg7iP6v",
        "outputId": "a4e05f30-9f0d-440b-a7da-45a93f767dc1"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.137, 'neu': 0.76, 'pos': 0.103, 'compound': -0.9802}"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(reddit_string6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFAWOqdoiRtS",
        "outputId": "d8b6cb66-2eab-4b06-9b74-fd1bcdc70ffd"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.106, 'neu': 0.795, 'pos': 0.099, 'compound': 0.9313}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "saveddataframe.to_csv('allreddittastrikeposts.csv', encoding = 'utf-8-sig') \n",
        "files.download('allreddittastrikeposts.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Z8ilE346cP5X",
        "outputId": "f682b39c-e476-458a-b86a-a552fcee6cc8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12d7a9dd-88a5-456a-a54c-4a06f3b556cc\", \"alltastrikeposts.csv\", 430665)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}